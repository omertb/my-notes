source: https://www.katacoda.com/courses/kubernetes

### 1 - Initialise Master
Install kubeadm.

* The command below will initialise the cluster:
```Shell
master $ kubeadm init --token=102952.1a7dd4cc8d1f4cc5 --kubernetes-version $(kubeadm version -o short)
```

> In production, it's recommend to exclude the token causing kubeadm to generate one on your behalf.

* To manage the Kubernetes cluster, the client configuration and certificates are required. This configuration is created when kubeadm initialises the cluster. The command copies the configuration to the users home directory and sets the environment variable for use with the CLI.
```Shell
master $ sudo cp /etc/kubernetes/admin.conf $HOME/
master $ sudo chown $(id -u):$(id -g) $HOME/admin.conf
master $ export KUBECONFIG=$HOME/admin.conf
```

### 2 - Deploy Container Networking Interface (CNI)
The Container Network Interface (CNI) defines how the different nodes and their workloads should
communicate. There are multiple network providers available, some are listed [here](https://kubernetes.io/docs/admin/addons/).

We'll use WeaveWorks:
```Shell
master $ wget "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')" -O weave-kube
master $ kubectl apply -f weave-kube

```
> Weave will now deploy as a series of Pods on the cluster. The status of this can be viewed using the command:
```Shell
master $ kubectl get pod -n kube-system
```

### 3 - Join Cluster
> _Once the Master and CNI has initialised, additional nodes can join the cluster as long as they have the correct token.
 The tokens can be managed via kubeadm token, for example:_ `kubecadm token list`

```Shell
master $ kubeadm token list
TOKEN                     TTL       EXPIRES                USAGES                   DESCRIPTION                       EXTRA GROUPS
102952.1a7dd4cc8d1f4cc5   23h       2019-12-06T16:42:19Z   authentication,signing   The default bootstrap token generated by 'kubeadm init'.   system:bootstrappers:kubeadm:default-node-token
```
* On the second node, run the command to join the cluster providing the IP address of the Master node.
```Shell
node01 $ kubeadm join --discovery-token-unsafe-skip-ca-verification --token=102952.1a7dd4cc8d1f4cc5 172.17.0.69:6443
```

This is the same command provided after the Master has been initialised.

> The --discovery-token-unsafe-skip-ca-verification` tag is used to bypass the Discovery Token verification. 
As this token is generated dynamically, we couldn't include it within the steps. When in production, use the
token provided by kubeadm init`.`

### 4 - View Nodes

The cluster has now been initialised. The Master node will manage the cluster, while our one worker node will run our
container workloads.

The Kubernetes CLI, known as kubectl, can now use the configuration to access the cluster.
For example, the command below will return the two nodes in our cluster.
```Shell
# kubectl get nodes
```

### 5 - Deploy Pod
The state of the two nodes in the cluster should now be Ready. This means that our deployments can be scheduled and launched.

Using Kubectl, it's possible to deploy pods. Commands are always issued for the Master with each node only responsible for executing the workloads.

* The command below create a Pod based on the Docker Image katacoda/docker-http-server:
```Shell
master $ kubectl create deployment http --image=katacoda/docker-http-server:latest
master $ kubectl get pods
NAME                    READY   STATUS              RESTARTS   AGE
http-7f8cbdf584-ccrtt   0/1     ContainerCreating   0          7s
master $ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
http-7f8cbdf584-ccrtt   1/1     Running   0          10s
```
> Once running, you can see the Docker Container running on the node.
```Shell
node01 $ docker ps | grep docker-http-server
```

### 5 - Deploy Dashboard

* Deploy the dashboard yaml with the command `kubectl apply -f dashboard.yaml`

* The dashboard is deployed into the kube-system namespace. View the status of the deployment with kubectl get pods -n kube-system`

> A ServiceAccount is required to login. A ClusterRoleBinding is used to assign the new ServiceAccount
(_admin-user_) the role of _cluster-admin_ on the cluster.

```Shell
master $ cat <<EOF | kubectl create -f - 
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kube-system
EOF

```

This means they can control all aspects of Kubernetes. With ClusterRoleBinding and RBAC, different level of permissions
can be defined based on security requirements. More information on creating a user for the Dashboard can be found in
the [Dashboard documentation](https://github.com/kubernetes/dashboard/wiki/Creating-sample-user).

* Once the ServiceAccount has been created, the token to login can be found with:
```Shell
master $ kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')
```

> When the dashboard was deployed, it used externalIPs to bind the service to port 8443. This makes the dashboard
available to outside of the cluster and viewable at https://2886795372-8443-elsy04.environments.katacoda.com/

* Use the admin-user token to access the dashboard.

>For production, instead of externalIPs, it's recommended to use `kubectl proxy to access the dashboard. 
See more details at [https://github.com/kubernetes/dashboard](https://github.com/kubernetes/dashboard.).

### 6 - Creating a Deployment, Starting a Container

```
$ kubectl run http --image=katacoda/docker-http-server:latest --replicas=1
$ kubectl get deployments  # view status of deployments
$ kubectl describe deployment http  # view how many replicas are available,
## labels specified and the events associated with the deploymen
```

### 7 - Exposing a Port

* Use the following command to expose the container port 80 on the host 8000 binding to the external-ip of the host.
```
# kubectl expose deployment http --external-ip="172.17.0.72" --port=8000 --target-port=80
```
> With kubectl run it's possible to create the deployment and expose it as a single command.

* Use the command below to create a second http service exposed on port 8001.
```
kubectl run httpexposed --image=katacoda/docker-http-server:latest --replicas=1 --port=80 --hostport=8001
```

>Under the covers, this exposes the Pod via Docker Port Mapping. As a result, you will not see the service listed using:
`kubectl get svc

> To find the details you can use `docker ps | grep httpexposed`

#### Pause Containers
Running the above command you'll notice the ports are exposed on the Pod, not the http container itself.
The Pause container is responsible for defining the network for the Pod. Other containers in the pod share the same
network namespace. This improves network performance and allow multiple containers to communicate over the same
network interface.

### 8 - Scale Containers

The command kubectl scale allows us to adjust the number of Pods running for a particular deployment or replication
controller.
```
$ kubectl scale --replicas=3 deployment http
$ kubectl get pods
$ kubectl describe svc http  # view the endpoint and the associated Pods which are included.
```